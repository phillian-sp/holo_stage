Timer unit: 1e-09 s

Total time: 0.00856782 s
File: /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py
Function: load_max_connected at line 99

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    99                                           @line_profiler.profile
   100                                           def load_max_connected(data, user2node, product2node):
   101         2      56670.0  28335.0      0.7      assert data.edge_index is not None
   102                                           
   103                                               # Convert to scipy sparse matrix
   104         2    5309595.0    3e+06     62.0      adj = to_scipy_sparse_matrix(data.edge_index, num_nodes=data.num_nodes)
   105                                           
   106                                               # Find connected components
   107         4     774812.0 193703.0      9.0      num_components, component_labels = sp.csgraph.connected_components(
   108         2        820.0    410.0      0.0          adj, connection="weak"
   109                                               )
   110                                           
   111         2        660.0    330.0      0.0      if num_components <= 1:
   112                                                   return (
   113                                                       data,
   114                                                       user2node,
   115                                                       product2node,
   116                                                   )  # Return original mappings if only one component
   117                                           
   118                                               # Find the largest component
   119         2     149080.0  74540.0      1.7      _, counts = np.unique(component_labels, return_counts=True)
   120         2      25640.0  12820.0      0.3      largest_component_label = np.argmax(counts)
   121         2      17530.0   8765.0      0.2      subset_np = component_labels == largest_component_label
   122         2      90140.0  45070.0      1.1      subset = torch.from_numpy(subset_np).to(data.edge_index.device, dtype=torch.bool)
   123                                           
   124                                               # Create a subgraph with only the largest connected component
   125         2    1918305.0 959152.5     22.4      sub_data = data.subgraph(subset)
   126                                           
   127                                               # Update user and product node mappings
   128         4      38670.0   9667.5      0.5      node_idx_mapping = {
   129         2     132841.0  66420.5      1.6          old_idx.item(): i for i, old_idx in enumerate(torch.where(subset)[0])
   130                                               }
   131         4      13660.0   3415.0      0.2      new_user2node = {
   132                                                   user: node_idx_mapping[node_id]
   133         2        770.0    385.0      0.0          for user, node_id in user2node.items()
   134                                                   if node_id in node_idx_mapping
   135                                               }
   136         4      37710.0   9427.5      0.4      new_product2node = {
   137                                                   product: node_idx_mapping[node_id]
   138         2        510.0    255.0      0.0          for product, node_id in product2node.items()
   139                                                   if node_id in node_idx_mapping
   140                                               }
   141         2        410.0    205.0      0.0      return sub_data, new_user2node, new_product2node

Total time: 0.0272779 s
File: /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py
Function: build_product_product_graph at line 145

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   145                                           @line_profiler.profile
   146                                           def build_product_product_graph(data, up_user2node, up_product2node):
   147                                           
   148         2     723933.0 361966.5      2.7      adj = to_torch_sparse_tensor(data.edge_index, size=(data.num_nodes, data.num_nodes))
   149         2    1189573.0 594786.5      4.4      twohopsadj = adj.T @ adj
   150                                           
   151         2        610.0    305.0      0.0      edge_index = []
   152                                           
   153        38       7010.0    184.5      0.0      for p1 in up_product2node.keys():
   154       884     180500.0    204.2      0.7          for p2 in up_product2node.keys():
   155                                           
   156       848     117521.0    138.6      0.4              if p1 == p2:
   157        36       3840.0    106.7      0.0                  continue
   158      2144     663733.0    309.6      2.4              for r in range(
   159       812   23625043.0  29094.9     86.6                  twohopsadj[up_product2node[p1], up_product2node[p2]].int().item()
   160                                                       ):
   161       520     403080.0    775.2      1.5                  edge_index.append([up_product2node[p1], up_product2node[p2]])
   162                                           
   163         4      98431.0  24607.8      0.4      return Data(
   164         2      10480.0   5240.0      0.0          price=data.price,
   165         2       4080.0   2040.0      0.0          category_code=data.category_code,
   166         2       2760.0   1380.0      0.0          brand=data.brand,
   167         2     234850.0 117425.0      0.9          edge_index=torch.tensor(edge_index).T,
   168         2      12420.0   6210.0      0.0          num_nodes=data.num_nodes,
   169                                               )

Total time: 0.127446 s
File: /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py
Function: compute_probabilities at line 176

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   176                                           @line_profiler.profile
   177                                           def compute_probabilities(data, features_keys):
   178                                           
   179         8       6250.0    781.2      0.0      feature_values = dict.fromkeys(
   180         4        610.0    152.5      0.0          features_keys, None
   181                                               )  # Store distinct values for each feature
   182         4        690.0    172.5      0.0      marginal_probabilities = {}  # P(F_A = a)
   183         4        680.0    170.0      0.0      conditional_probabilities = {}  # P(F_{A|N} = a | F_{B|C} = b)
   184         4        540.0    135.0      0.0      internal_conditional_probabilities = {}  # P(F_{A|C} = a | F_{B|C} = b)
   185                                           
   186        16       3410.0    213.1      0.0      for feature in features_keys:
   187        12     253650.0  21137.5      0.2          feature_values[feature] = set(data[feature])
   188                                           
   189         4        670.0    167.5      0.0      total_feature_nodes = 0
   190                                           
   191                                               # Compute marginal probabilities
   192        16       4920.0    307.5      0.0      for feature in feature_values:
   193        12     280320.0  23360.0      0.2          mask = ~torch.isinf(data[feature])
   194        12      91700.0   7641.7      0.1          total_feature_nodes = torch.sum(mask).item()
   195                                           
   196        12       4500.0    375.0      0.0          marginal_probabilities[feature] = {}
   197        12       2330.0    194.2      0.0          if (
   198        12       3170.0    264.2      0.0              feature == "price"
   199                                                   ):  # TODO: Can add a distinguisher between discrete and continous features
   200                                                       # TODO: Calculate reflect qunatile to ensure invariance,
   201                                                       # Compute cumulative probabilities for price
   202                                           
   203        84      20220.0    240.7      0.0              for i, value in enumerate(feature_values[feature]):
   204        80     514162.0   6427.0      0.4                  count = (data[feature] <= value).sum().item()
   205        80      67320.0    841.5      0.1                  marginal_probabilities[feature][value.item()] = (
   206        80      15160.0    189.5      0.0                      count / total_feature_nodes
   207                                                           )
   208                                                   else:
   209                                                       # Regular marginal probability calculation for non-price features
   210       168      29370.0    174.8      0.0              for value in feature_values[feature]:
   211       160     978752.0   6117.2      0.8                  count = (data[feature] == value).sum().item()
   212       160     116270.0    726.7      0.1                  marginal_probabilities[feature][value.item()] = (
   213       160      28080.0    175.5      0.0                      count / total_feature_nodes
   214                                                           )
   215                                           
   216       570     112870.0    198.0      0.1      for i in range(data.edge_index.size(-1)):
   217       566    4333244.0   7655.9      3.4          u, v = data.edge_index[0, i], data.edge_index[1, i]
   218                                                   # TODO: Distinguish between discrete and continous features (ball method or not), currently kept simple
   219      2264     407082.0    179.8      0.3          for feature1 in features_keys:
   220      6792    1360425.0    200.3      1.1              for feature2 in features_keys:
   221      5094   73145707.0  14359.2     57.4                  if torch.isinf(data[feature1][u]) or torch.isinf(data[feature2][v]):
   222                                                               continue
   223                                           
   224      4680    1004222.0    214.6      0.8                  key = (
   225      4680     715803.0    152.9      0.6                      feature1,
   226      4680   12999705.0   2777.7     10.2                      data[feature1][u].item(),
   227      4680     694343.0    148.4      0.5                      feature2,
   228      4680   11219160.0   2397.3      8.8                      data[feature2][v].item(),
   229                                                           )
   230      4680    1478062.0    315.8      1.2                  conditional_probabilities[key] = (
   231      4680    2026172.0    432.9      1.6                      conditional_probabilities.get(key, 0) + 1
   232                                                           )
   233                                           
   234        84      38700.0    460.7      0.0      for i in range(data.num_nodes):
   235       320      60960.0    190.5      0.0          for feature1 in features_keys:
   236       960     198310.0    206.6      0.2              for feature2 in features_keys:
   237       720    9790423.0  13597.8      7.7                  if torch.isinf(data[feature1][i]) or torch.isinf(data[feature2][i]):
   238                                                               continue
   239                                           
   240       648     148450.0    229.1      0.1                  key = (
   241       648     121652.0    187.7      0.1                      feature1,
   242       648    1621468.0   2502.3      1.3                      data[feature1][i].item(),
   243       648     105730.0    163.2      0.1                      feature2,
   244       648    1373697.0   2119.9      1.1                      data[feature2][i].item(),
   245                                                           )
   246       648     359720.0    555.1      0.3                  internal_conditional_probabilities[key] = (
   247       648     280440.0    432.8      0.2                      internal_conditional_probabilities.get(key, 0) + 1
   248                                                           )
   249                                           
   250                                               # Normalize conditional probabilities
   251       605     109890.0    181.6      0.1      for key in conditional_probabilities:
   252       601     942262.0   1567.8      0.7          conditional_probabilities[key] /= data.edge_index.size(-1)
   253                                           
   254       312      56570.0    181.3      0.0      for key in internal_conditional_probabilities:
   255       924     216320.0    234.1      0.2          internal_conditional_probabilities[
   256       308      50661.0    164.5      0.0              key
   257       308      48210.0    156.5      0.0          ] /= total_feature_nodes  # assume all featured nodes have non-inf values in all features
   258                                           
   259         4        900.0    225.0      0.0      return (
   260         4        710.0    177.5      0.0          marginal_probabilities,
   261         4        780.0    195.0      0.0          conditional_probabilities,
   262         4        800.0    200.0      0.0          internal_conditional_probabilities,
   263                                               )

Total time: 1.29222 s
File: /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py
Function: get_user_product_graph at line 13

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    13                                           @line_profiler.profile
    14                                           def get_user_product_graph(csv_file_path, start_row, end_row, category):
    15         2       1520.0    760.0      0.0      if category is None:
    16                                                   category = "electronics.smartphone"
    17         4    2940749.0 735187.2      0.2      df_chunks = pd.read_csv(
    18         2        480.0    240.0      0.0          csv_file_path, chunksize=100000
    19                                               )  # Adjust chunksize based on your memory capacity
    20                                           
    21         2        650.0    325.0      0.0      user2node = {}  # from user id to node id
    22         2        380.0    190.0      0.0      product2node = {}  # from product id to node id
    23         2        450.0    225.0      0.0      edge_index = []
    24         2        330.0    165.0      0.0      edge_attr = []
    25         2       1190.0    595.0      0.0      event_type_mapping = {
    26         2        450.0    225.0      0.0          "view": 0,
    27         2        410.0    205.0      0.0          "cart": 1,
    28         2        380.0    190.0      0.0          "purchase": 2,
    29         2        450.0    225.0      0.0          "remove_from_cart": 3,
    30                                               }  # Mapping event types to integers
    31                                           
    32         2        380.0    190.0      0.0      category_codes = []
    33         2        340.0    170.0      0.0      cat_map = {}
    34         2        340.0    170.0      0.0      brands = []
    35         2        390.0    195.0      0.0      brand_map = {}
    36         2        340.0    170.0      0.0      prices = []
    37                                           
    38                                               # Process each chunk
    39         2        330.0    165.0      0.0      count = 0
    40         2        370.0    185.0      0.0      break_flag = False
    41         4  386510949.0    1e+08     29.9      for df in df_chunks:
    42         4       4180.0   1045.0      0.0          if break_flag:
    43         2        860.0    430.0      0.0              break
    44     16500  801526978.0  48577.4     62.0          for _, row in df.iterrows():
    45     16500   92089065.0   5581.2      7.1              if row["category_code"] != category:
    46     16198    2266507.0    139.9      0.2                  continue
    47       302      78771.0    260.8      0.0              count += 1
    48       302     200991.0    665.5      0.0              if count < start_row:
    49        99      14270.0    144.1      0.0                  continue
    50       203      48592.0    239.4      0.0              if count > end_row:
    51         2        760.0    380.0      0.0                  break_flag = True
    52         2      31660.0  15830.0      0.0                  break
    53       201     807550.0   4017.7      0.1              user_id = row["user_id"]
    54       201     759586.0   3779.0      0.1              product_id = row["product_id"]
    55       201     708702.0   3525.9      0.1              category_code = row["category_code"]
    56       201     724111.0   3602.5      0.1              brand = row["brand"]
    57                                           
    58       201      52840.0    262.9      0.0              if category_code not in cat_map:
    59         2       1610.0    805.0      0.0                  cat_map[category_code] = len(cat_map)
    60                                           
    61       201      60450.0    300.7      0.0              if brand not in brand_map:
    62        29      14060.0    484.8      0.0                  brand_map[brand] = len(brand_map)
    63                                           
    64       201      57800.0    287.6      0.0              if user_id not in user2node:
    65        60      38800.0    646.7      0.0                  user2node[user_id] = len(product2node) + len(user2node)
    66                                           
    67        60      62460.0   1041.0      0.0                  prices.append(float("inf"))
    68        60      24990.0    416.5      0.0                  category_codes.append(float("inf"))
    69        60      23240.0    387.3      0.0                  brands.append(float("inf"))
    70       201      51480.0    256.1      0.0              if product_id not in product2node:
    71       141      87030.0    617.2      0.0                  product2node[product_id] = len(product2node) + len(user2node)
    72                                           
    73       141     581934.0   4127.2      0.0                  prices.append(row["price"])
    74       141      51110.0    362.5      0.0                  category_codes.append(cat_map[category_code])
    75       141      53390.0    378.7      0.0                  brands.append(brand_map[brand])
    76                                           
    77       201      53960.0    268.5      0.0              user_node = user2node[user_id]
    78       201      49970.0    248.6      0.0              product_node = product2node[product_id]
    79                                           
    80                                                       # only from user to product, the reverse will be added later
    81       201      77840.0    387.3      0.0              edge_index.append([user_node, product_node])
    82       201     774462.0   3853.0      0.1              edge_attr.append(event_type_mapping[row["event_type"]])
    83                                           
    84                                               # Convert to tensors
    85         2     972692.0 486346.0      0.1      edge_index_tensor = torch.tensor(edge_index).t()
    86         2      29230.0  14615.0      0.0      edge_attr_tensor = torch.tensor(edge_attr)
    87                                           
    88         4     274661.0  68665.2      0.0      data = Data(
    89         2      41070.0  20535.0      0.0          price=torch.tensor(prices),
    90         2      27800.0  13900.0      0.0          category_code=torch.tensor(category_codes),
    91         2      27890.0  13945.0      0.0          brand=torch.tensor(brands),
    92         2        620.0    310.0      0.0          edge_index=edge_index_tensor,
    93         2        570.0    285.0      0.0          edge_attr=edge_attr_tensor,
    94         2       2240.0   1120.0      0.0          num_nodes=len(user2node) + len(product2node),
    95                                               )
    96         2       1980.0    990.0      0.0      feature_keys = ["price", "category_code", "brand"]
    97         2        590.0    295.0      0.0      return data, user2node, product2node, feature_keys

Total time: 9.68834 s
File: /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py
Function: build_edge_graph at line 265

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   265                                           @line_profiler.profile
   266                                           def build_edge_graph(
   267                                               data, u, v, marginal_prob, conditional_prob, internal_conditional_prob
   268                                           ):
   269       520     154072.0    296.3      0.0      tuple2node = {}
   270       520     107880.0    207.5      0.0      x = []
   271       520      90170.0    173.4      0.0      edge_index = []
   272       520      92342.0    177.6      0.0      edge_attr = []
   273                                           
   274                                               # Add edges based on conditional probabilities
   275                                               # Only add edges if both features are present in either node u or v
   276    224854   50033812.0    222.5      0.5      for (
   277    224334   32492235.0    144.8      0.3          feature_u,
   278    224334   25627624.0    114.2      0.3          value_u,
   279    224334   27770654.0    123.8      0.3          feature_v,
   280    224334   25124186.0    112.0      0.3          value_v,
   281    224854   28695416.0    127.6      0.3      ), prob in conditional_prob.items():
   282    224334 1730260068.0   7712.9     17.9          hasfeature_u = ~torch.isinf(data[feature_u])
   283    224334 1537870426.0   6855.3     15.9          hasfeature_v = ~torch.isinf(data[feature_v])
   284    224334  926086181.0   4128.2      9.6          if (hasfeature_u[u] and hasfeature_v[v]) or (
   285                                                       hasfeature_v[u] and hasfeature_u[v]
   286                                                   ):
   287                                                       # Ensure both feature values match those in u or v before adding the edge
   288    224334 1672810333.0   7456.8     17.3              if value_u == data[feature_u][u] and value_v == data[feature_v][v]:
   289      4680    2473450.0    528.5      0.0                  if (feature_u, value_u, u) not in tuple2node:
   290       646     458202.0    709.3      0.0                      tuple2node[(feature_u, value_u, u)] = len(tuple2node)
   291       646     389070.0    602.3      0.0                      x.append(marginal_prob[feature_u][value_u])
   292      4680    1472282.0    314.6      0.0                  if (feature_v, value_v, v) not in tuple2node:
   293      1369     753261.0    550.2      0.0                      tuple2node[(feature_v, value_v, v)] = len(tuple2node)
   294      1369     659232.0    481.5      0.0                      x.append(marginal_prob[feature_v][value_v])
   295                                           
   296      9360    2509166.0    268.1      0.0                  edge_index.append(
   297      4680    1002034.0    214.1      0.0                      [
   298      4680    1317875.0    281.6      0.0                          tuple2node[(feature_u, value_u, u)],
   299      4680    1183362.0    252.9      0.0                          tuple2node[(feature_v, value_v, v)],
   300                                                               ]
   301                                                           )
   302      4680    1302667.0    278.3      0.0                  edge_attr.append(prob)
   303                                           
   304    224334 1622213385.0   7231.2     16.7              if value_u == data[feature_u][v] and value_v == data[feature_v][u]:
   305      4680    2387597.0    510.2      0.0                  if (feature_u, value_u, v) not in tuple2node:
   306       191     113590.0    594.7      0.0                      tuple2node[(feature_u, value_u, v)] = len(tuple2node)
   307       191     111500.0    583.8      0.0                      x.append(marginal_prob[feature_u][value_u])
   308      4680    1625332.0    347.3      0.0                  if (feature_v, value_v, u) not in tuple2node:
   309       914     581485.0    636.2      0.0                      tuple2node[(feature_v, value_v, u)] = len(tuple2node)
   310       914     500171.0    547.2      0.0                      x.append(marginal_prob[feature_v][value_v])
   311                                           
   312      9360    2690203.0    287.4      0.0                  edge_index.append(
   313      4680    1046963.0    223.7      0.0                      [
   314      4680    1453394.0    310.6      0.0                          tuple2node[(feature_u, value_u, v)],
   315      4680    1335673.0    285.4      0.0                          tuple2node[(feature_v, value_v, u)],
   316                                                               ]
   317                                                           )
   318      4680    1245603.0    266.2      0.0                  edge_attr.append(prob)
   319                                           
   320                                                           # TODO: Can add relationship type (same feature, opposite node) or
   321                                                           # (different feature, opposite node) or (different feature, same node)
   322                                           
   323     52276   13792991.0    263.8      0.1      for (
   324     51756    9637950.0    186.2      0.1          feature_u,
   325     51756    8192088.0    158.3      0.1          value_u,
   326     51756    8600039.0    166.2      0.1          feature_v,
   327     51756    8799665.0    170.0      0.1          value_v,
   328     52276    9680039.0    185.2      0.1      ), prob in internal_conditional_prob.items():
   329     51756  403489584.0   7796.0      4.2          hasfeature_u = ~torch.isinf(data[feature_u])
   330     51756  365846755.0   7068.7      3.8          hasfeature_v = ~torch.isinf(data[feature_v])
   331     51756  218080080.0   4213.6      2.3          if (hasfeature_u[u] and hasfeature_v[u]) or (
   332                                                       hasfeature_u[v] and hasfeature_v[v]
   333                                                   ):
   334     51756  444717274.0   8592.6      4.6              if value_u == data[feature_u][u] and value_v == data[feature_v][u]:
   335      4680    2342366.0    500.5      0.0                  if (feature_u, value_u, u) not in tuple2node:
   336                                                               tuple2node[(feature_u, value_u, u)] = len(tuple2node)
   337                                                               x.append(marginal_prob[feature_u][value_u])
   338      4680    1602174.0    342.3      0.0                  if (feature_v, value_v, u) not in tuple2node:
   339                                                               tuple2node[(feature_v, value_v, u)] = len(tuple2node)
   340                                                               x.append(marginal_prob[feature_v][value_v])
   341                                           
   342      9360    3162364.0    337.9      0.0                  edge_index.append(
   343      4680    1207501.0    258.0      0.0                      [
   344      4680    1495865.0    319.6      0.0                          tuple2node[(feature_u, value_u, u)],
   345      4680    1466772.0    313.4      0.0                          tuple2node[(feature_v, value_v, u)],
   346                                                               ]
   347                                                           )
   348      4680    1437466.0    307.2      0.0                  edge_attr.append(prob)
   349                                           
   350     51756  431667070.0   8340.4      4.5              if value_u == data[feature_u][v] and value_v == data[feature_v][v]:
   351      4680    2295005.0    490.4      0.0                  if (feature_u, value_u, v) not in tuple2node:
   352                                                               tuple2node[(feature_u, value_u, v)] = len(tuple2node)
   353                                                               x.append(marginal_prob[feature_u][value_u])
   354      4680    1643504.0    351.2      0.0                  if (feature_v, value_v, v) not in tuple2node:
   355                                                               tuple2node[(feature_v, value_v, v)] = len(tuple2node)
   356                                                               x.append(marginal_prob[feature_v][value_v])
   357                                           
   358      9360    3114631.0    332.8      0.0                  edge_index.append(
   359      4680    1212111.0    259.0      0.0                      [
   360      4680    1557513.0    332.8      0.0                          tuple2node[(feature_u, value_u, v)],
   361      4680    1415132.0    302.4      0.0                          tuple2node[(feature_v, value_v, v)],
   362                                                               ]
   363                                                           )
   364      4680    1404995.0    300.2      0.0                  edge_attr.append(prob)
   365                                           
   366      1040   16490971.0  15856.7      0.2      return Data(
   367       520    5567174.0  10706.1      0.1          x=torch.tensor(x).view(-1, 1),
   368       520    9279625.0  17845.4      0.1          edge_index=torch.tensor(edge_index).T,
   369       520    3101957.0   5965.3      0.0          edge_attr=torch.tensor(edge_attr),
   370                                               )

  0.01 seconds - /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py:99 - load_max_connected
  0.03 seconds - /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py:145 - build_product_product_graph
  0.13 seconds - /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py:176 - compute_probabilities
  1.29 seconds - /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py:13 - get_user_product_graph
  9.69 seconds - /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py:265 - build_edge_graph
