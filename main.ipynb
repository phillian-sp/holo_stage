{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can STAGE Handle the Pressure? Testing Its Generalizability Across Graph Models\n",
    "In this notebook, we provide an overview of our implementation of STAGE and the various model architectures we explored. Given the size of our codebase, we focus on showcasing the key components of the code. For clarity, we have copied the implementation of each model into this notebook and included explanations of their main components. \n",
    "\n",
    "**Note that the code cells are for reference only and are not executable. At the end of the notebook, we have included a bash script to facilitate the full training and evaluation of the models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGCNConv\n",
    "The implementation of RGCNConv is in the file `nbfnet/edge_rgcn_conv.py`. However, to make the code more readable, we copied the implementation of RGCN to this notebook in the following code cell.\n",
    "\n",
    "#### Incorporating Edge Features in RGCNConv\n",
    "In traditional RGCNConv implementations, the focus is primarily on node features and relation types, while edge attributes (such as edge weights or embeddings) are often ignored or treated as static. For our use case, it is critical to incorporate edge features directly into the message-passing framework to enrich the representation power of the model.\n",
    "\n",
    "This modified RGCNConv implementation, shown in the provided code snippet, extends the standard RGCNConv to handle edge embeddings. These are seamlessly integrated into the message-passing phase by:\n",
    "1. Transforming Edge Embeddings: Depending on the edge_method, edge embeddings are either transformed via a learnable linear layer (edgegraph_mlp) or left unaltered.\n",
    "2. Combining Messages and Edge Embeddings: Depending on the edge_method, the edge embeddings are either concatenated with the node messages or added directly to them.\n",
    "\n",
    "#### Efficiency Improvements\n",
    "This implementation introduces several optimizations to make the enhanced RGCNConv practical for large graphs:\n",
    "1. Basis Decomposition: For graphs with many relation types, maintaining separate weight matrices for each type can be computationally prohibitive. Basis decomposition reduces the number of parameters while still allowing expressive modeling of relations.\n",
    "2. Sparse Operations: By leveraging PyTorch Geometric’s scatter operations, the implementation avoids dense adjacency matrix computations, allowing it to scale efficiently to large, sparse graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch_scatter import scatter\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.inits import glorot\n",
    "\n",
    "class RGCNConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    A relational graph convolutional network (RGCN) layer with additional edge features.\n",
    "    Supports edge embeddings, multiple aggregation strategies, and various update mechanisms.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Dimension of input node features.\n",
    "        output_dim (int): Dimension of output node features.\n",
    "        num_relation (int): Number of relation types.\n",
    "        aggregate_func (str): Aggregation function ('add', 'mean', 'max', etc.).\n",
    "        layer_norm (bool): Whether to apply layer normalization.\n",
    "        activation (str or Callable): Activation function to use (e.g., 'relu', 'tanh').\n",
    "        num_bases (int, optional): Number of bases for relation weight decomposition. Defaults to 0.\n",
    "        edge_method (str): Determines how edge features are used ('method1', 'method2', etc.).\n",
    "        edge_embed_dim (int, optional): Dimension of edge embeddings. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        num_relation,\n",
    "        aggregate_func,\n",
    "        layer_norm,\n",
    "        activation,\n",
    "        num_bases=0,\n",
    "        edge_method=\"method1\",\n",
    "        edge_embed_dim=None,\n",
    "    ):\n",
    "        super(RGCNConv, self).__init__()\n",
    "\n",
    "        # Initialize layer parameters\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_relation = num_relation\n",
    "        self.aggregate_func = aggregate_func\n",
    "        self.edge_embed_dim = edge_embed_dim\n",
    "        self.num_bases = num_bases\n",
    "\n",
    "        # Determine edge processing strategy\n",
    "        if edge_method in [\"method1\", \"method2\"]:\n",
    "            self.stage_method = \"add\"\n",
    "        else:\n",
    "            self.stage_method = \"cat\"\n",
    "        self.transform_edge = edge_method in [\"method2\", \"method4\"]\n",
    "\n",
    "        # Initialize layer normalization if specified\n",
    "        self.layer_norm = nn.LayerNorm(output_dim) if layer_norm else None\n",
    "\n",
    "        # Initialize activation function\n",
    "        self.activation = getattr(F, activation) if isinstance(activation, str) else activation\n",
    "\n",
    "        # Linear transformation for node updates\n",
    "        self.lin_s = nn.Linear(input_dim, output_dim)\n",
    "        nn.init.xavier_uniform_(self.lin_s.weight)\n",
    "\n",
    "        # Linear transformation for edge and node combination\n",
    "        if self.stage_method == \"cat\":\n",
    "            assert edge_embed_dim is not None, \"edge_embed_dim must be specified for concatenation\"\n",
    "            self.lin_f = nn.Linear(edge_embed_dim + input_dim, output_dim)\n",
    "            nn.init.xavier_uniform_(self.lin_f.weight)\n",
    "        elif self.stage_method == \"add\":\n",
    "            self.lin_f = nn.Identity()\n",
    "\n",
    "        # Edge embedding transformation\n",
    "        if edge_embed_dim is not None:\n",
    "            self.edgegraph_mlp = nn.Linear(edge_embed_dim, output_dim)\n",
    "            nn.init.xavier_uniform_(self.edgegraph_mlp.weight)\n",
    "\n",
    "        # Relation weight initialization\n",
    "        if num_bases > 0:\n",
    "            self.weight = nn.Parameter(torch.empty(num_bases, input_dim, output_dim))\n",
    "            self.comp = nn.Parameter(torch.empty(num_relation, num_bases))\n",
    "            glorot(self.weight)\n",
    "            glorot(self.comp)\n",
    "        else:\n",
    "            self.lin_r = nn.ModuleList([nn.Linear(input_dim, output_dim) for _ in range(num_relation)])\n",
    "            for lin in self.lin_r:\n",
    "                nn.init.xavier_uniform_(lin.weight)\n",
    "\n",
    "    def forward(self, input, edge_index, edge_type, edge_weight=None, edge_embed=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the EdgeRGCNConv layer.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): Node features of shape (num_nodes, input_dim).\n",
    "            edge_index (torch.Tensor): Edge indices of shape (2, num_edges).\n",
    "            edge_type (torch.Tensor): Edge type indices of shape (num_edges,).\n",
    "            edge_weight (torch.Tensor, optional): Edge weights of shape (num_edges,). Defaults to None.\n",
    "            edge_embed (torch.Tensor, optional): Edge feature embeddings. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Updated node features of shape (num_nodes, output_dim).\n",
    "        \"\"\"\n",
    "        num_node = input.size(0)\n",
    "\n",
    "        # Default edge weight is 1 for all edges\n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones(len(edge_type), device=input.device)\n",
    "\n",
    "        # Ensure edge embeddings are handled correctly\n",
    "        edge_type = edge_type.to(torch.long)\n",
    "        edge_embed = edge_embed if edge_embed is not None else 0\n",
    "\n",
    "        # Perform message passing\n",
    "        output = self.propagate(\n",
    "            edge_index=edge_index,\n",
    "            input=input,\n",
    "            edge_type=edge_type,\n",
    "            edge_embed=edge_embed,\n",
    "            size=(num_node, num_node),\n",
    "            edge_weight=edge_weight,\n",
    "        )\n",
    "        return output\n",
    "\n",
    "    def message(self, input_j, edge_type, edge_embed):\n",
    "        \"\"\"\n",
    "        Compute messages to be passed along edges.\n",
    "\n",
    "        Args:\n",
    "            input_j (torch.Tensor): Source node features of shape (num_edges, input_dim).\n",
    "            edge_type (torch.Tensor): Edge type indices of shape (num_edges,).\n",
    "            edge_embed (torch.Tensor): Edge feature embeddings.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Messages of shape (num_edges, output_dim).\n",
    "        \"\"\"\n",
    "        # Compute relation-specific messages\n",
    "        num_edges, _ = input_j.size()\n",
    "        message = torch.zeros((num_edges, self.output_dim), device=input_j.device)\n",
    "        # compute weight if using basis decomposition\n",
    "        if self.num_bases > 0:\n",
    "            weight = (self.comp @ self.weight.view(self.num_bases, -1)).view(\n",
    "                self.num_relation, self.input_dim, self.output_dim\n",
    "            )\n",
    "        for rel_type in range(self.num_relation):\n",
    "            mask = (edge_type == rel_type).unsqueeze(-1)\n",
    "            # rel_mapped: (batch_size, num_edges, self.output_dim)\n",
    "            if self.num_bases > 0:\n",
    "                rel_mapped = torch.matmul(\n",
    "                    input_j,\n",
    "                    weight[rel_type],\n",
    "                )\n",
    "            else:\n",
    "                rel_mapped = self.lin_r[rel_type](input_j)\n",
    "            message += rel_mapped * mask\n",
    "\n",
    "        # Incorporate edge embeddings\n",
    "        transformed_edge_embed = self.edgegraph_mlp(edge_embed) if self.transform_edge else edge_embed\n",
    "        if self.stage_method == \"cat\":\n",
    "            message = torch.cat([message, transformed_edge_embed], dim=-1)\n",
    "        elif self.stage_method == \"add\":\n",
    "            message += transformed_edge_embed\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown stage method {self.stage_method}\")\n",
    "\n",
    "        return message\n",
    "\n",
    "    def aggregate(self, input, edge_weight, index, edge_type, dim_size):\n",
    "        \"\"\"\n",
    "        Aggregate messages from neighbors.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): Messages to aggregate.\n",
    "            edge_weight (torch.Tensor): Edge weights for scaling messages.\n",
    "            index (torch.Tensor): Target nodes of messages.\n",
    "            edge_type (torch.Tensor): Types of edges in the graph.\n",
    "            dim_size (int): Total number of nodes.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Aggregated messages.\n",
    "        \"\"\"\n",
    "        # Scale messages by edge weights\n",
    "        shape = [1] * input.ndim\n",
    "        shape[0] = -1\n",
    "        edge_weight = edge_weight.view(shape)\n",
    "        weighted_input = input * edge_weight\n",
    "\n",
    "        # Aggregate messages based on edge type\n",
    "        output = torch.zeros((dim_size, self.output_dim), device=input.device)\n",
    "        for rel_type in range(self.num_relation):\n",
    "            mask = edge_type == rel_type\n",
    "            output += scatter(\n",
    "                weighted_input[mask],\n",
    "                index[mask],\n",
    "                dim=0,\n",
    "                dim_size=dim_size,\n",
    "                reduce=self.aggregate_func,\n",
    "            )\n",
    "        return output\n",
    "\n",
    "    def update(self, update, input):\n",
    "        \"\"\"\n",
    "        Update node features after aggregation.\n",
    "\n",
    "        Args:\n",
    "            update (torch.Tensor): Aggregated messages of shape (num_nodes, output_dim).\n",
    "            input (torch.Tensor): Previous node features of shape (num_nodes, input_dim).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Updated node features.\n",
    "        \"\"\"\n",
    "        # Perform linear transformation and apply activation function\n",
    "        output = self.lin_s(input) + self.lin_f(update)\n",
    "        if self.layer_norm:\n",
    "            output = self.layer_norm(output)\n",
    "        if self.activation:\n",
    "            output = self.activation(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGCN Model\n",
    "The implementation of the RGCN model is in the file `nbfnet/rgcn.py`. The following code cell is a simplified version of the RGCN model for explaining purposes.\n",
    "\n",
    "The model consists of multiple RGCN layers implemented using the `EdgeRGCNConv` class, which extends the standard RGCN to handle edge embeddings. Each layer processes input node features, edge indices, edge types, and optional edge attributes to generate updated node features. These features are computed through relational message-passing and aggregation, with optional shortcut connections to facilitate training deeper models.\n",
    "\n",
    "The forward pass initializes node features with a placeholder tensor if no initial features are provided. It processes the graph structure (edge indices and types) and optional edge embeddings, propagating messages through the RGCN layers. The final output consists of node embeddings for triples in a batch, where each triple represents a source node, a relation, and a target node. The embeddings are then used to compute scores for link prediction tasks through dismult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "@dataclass\n",
    "class RGCNConfig:\n",
    "    \"\"\"\n",
    "    Configuration class for the RGCN model.\n",
    "\n",
    "    Attributes:\n",
    "        input_dim (int): Dimension of input node features.\n",
    "        num_layers (int): Number of RGCN layers.\n",
    "        aggregate_func (str): Aggregation function (e.g., \"mean\", \"add\", \"max\").\n",
    "        short_cut (int): Whether to use shortcut connections between layers.\n",
    "        layer_norm (int): Whether to apply layer normalization after each layer.\n",
    "        activation (str): Activation function to use (e.g., \"relu\").\n",
    "        concat_hidden (int): Whether to concatenate outputs of all layers.\n",
    "        num_bases (int): Number of bases for parameter sharing in relation modeling.\n",
    "        use_stage (int): Whether to enable STAGE features (edge embeddings).\n",
    "        edge_method (str): Method for handling edge embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    input_dim: int = 256\n",
    "    num_layers: int = 6\n",
    "    aggregate_func: str = \"mean\"\n",
    "    short_cut: int = 1\n",
    "    layer_norm: int = 1\n",
    "    activation: str = \"relu\"\n",
    "    concat_hidden: int = 0\n",
    "    num_bases: int = 0\n",
    "    use_stage: int = 1\n",
    "    edge_method: str = \"method1\"\n",
    "\n",
    "\n",
    "class RGCN(nn.Module):\n",
    "    \"\"\"\n",
    "    Relational Graph Convolutional Network (RGCN) with support for edge embeddings.\n",
    "\n",
    "    Args:\n",
    "        num_relation (int): Number of relation types.\n",
    "        edge_embed_dim (int or None): Dimension of edge embeddings (if applicable).\n",
    "        cfg (RGCNConfig): Configuration object for the RGCN.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_relation, edge_embed_dim, cfg: RGCNConfig):\n",
    "        super(RGCN, self).__init__()\n",
    "\n",
    "        # Disable edge embeddings if STAGE is not used\n",
    "        if not cfg.use_stage:\n",
    "            edge_embed_dim = None\n",
    "\n",
    "        # Initialize attributes\n",
    "        self.dims = [cfg.input_dim] * (cfg.num_layers + 1)  # Feature dimensions for all layers\n",
    "        self.num_relation = num_relation\n",
    "        self.short_cut = cfg.short_cut\n",
    "        self.concat_hidden = cfg.concat_hidden\n",
    "        self.edge_embed_dim = edge_embed_dim\n",
    "        self.num_bases = cfg.num_bases\n",
    "\n",
    "        # Define RGCN layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(self.dims) - 1):\n",
    "            self.layers.append(\n",
    "                RGCNConv(\n",
    "                    self.dims[i],\n",
    "                    self.dims[i + 1],\n",
    "                    num_relation,\n",
    "                    cfg.aggregate_func,\n",
    "                    cfg.layer_norm,\n",
    "                    cfg.activation,\n",
    "                    num_bases=cfg.num_bases,\n",
    "                    edge_method=cfg.edge_method,\n",
    "                    edge_embed_dim=edge_embed_dim,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Compute feature dimension if concatenating hidden states\n",
    "        feature_dim = cfg.input_dim * cfg.num_layers\n",
    "\n",
    "        # Embedding for relations\n",
    "        self.relation_emb = nn.Embedding(num_relation, cfg.input_dim)\n",
    "        nn.init.xavier_uniform_(self.relation_emb.weight, gain=nn.init.calculate_gain(cfg.activation))\n",
    "\n",
    "        # Define final linear layer if concatenating hidden states\n",
    "        if self.concat_hidden:\n",
    "            self.final_linear = nn.Linear(feature_dim, cfg.input_dim)\n",
    "\n",
    "        # Print number of parameters\n",
    "        num_params = sum(p.numel() for p in self.parameters())\n",
    "        print(f\"Number of parameters in RGCN: {num_params}\")\n",
    "\n",
    "    def forward(self, data: Data, batch: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the RGCN.\n",
    "\n",
    "        Args:\n",
    "            data (Data): PyTorch Geometric Data object containing the graph structure and features.\n",
    "            batch (torch.Tensor): Tensor of shape [batch_size, num_negative + 1, 3]\n",
    "                                   containing (source node, relation, target node) triples.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Scores for each triple in the batch.\n",
    "        \"\"\"\n",
    "        # Initialize node features as ones (placeholder for featureless input)\n",
    "        x = torch.ones((data.num_nodes, self.dims[0]), device=data.edge_index.device)\n",
    "\n",
    "        # Retrieve edge information from the data object\n",
    "        edge_index = data.edge_index  # Edge indices [2, num_edges]\n",
    "        edge_type = data.original_edge_type  # Edge types [num_edges]\n",
    "\n",
    "        # Retrieve edge embeddings if available\n",
    "        if self.edge_embed_dim is not None:\n",
    "            edge_embed = data.edge_embeddings  # Edge embeddings [num_edges, edge_embed_dim]\n",
    "        else:\n",
    "            edge_embed = None\n",
    "\n",
    "        # Retrieve edge weights if provided\n",
    "        edge_weight = data.edge_weight if hasattr(data, \"edge_weight\") else None\n",
    "\n",
    "        # To store outputs of all layers for concatenation (if enabled)\n",
    "        hidden_states = []\n",
    "\n",
    "        # Pass input through each RGCN layer\n",
    "        for layer in self.layers:\n",
    "            new_x = layer.forward(x, edge_index, edge_type, edge_weight, edge_embed)\n",
    "\n",
    "            # Apply shortcut connection if enabled\n",
    "            if self.short_cut:\n",
    "                new_x = new_x + x\n",
    "\n",
    "            # Update current node features\n",
    "            x = new_x\n",
    "            hidden_states.append(x)\n",
    "\n",
    "        # Concatenate hidden states if configured\n",
    "        if self.concat_hidden:\n",
    "            x = torch.cat(hidden_states, dim=-1)  # Concatenate along feature dimension\n",
    "            x = self.final_linear(x)  # Reduce concatenated features to output dimension\n",
    "\n",
    "        # Expand node embeddings for batch processing\n",
    "        x = x.expand(batch.size(0), -1, -1)\n",
    "\n",
    "        # Extract source and target node embeddings from the batch\n",
    "        source_nodes = batch[:, :, 0].unsqueeze(-1).expand(-1, -1, x.size(-1))\n",
    "        target_nodes = batch[:, :, 1].unsqueeze(-1).expand(-1, -1, x.size(-1))\n",
    "        relations = batch[:, :, 2]  # Relation indices\n",
    "\n",
    "        source_emb = x.gather(1, source_nodes)  # Source node embeddings\n",
    "        target_emb = x.gather(1, target_nodes)  # Target node embeddings\n",
    "        relation_emb = self.relation_emb(relations)  # Relation embeddings\n",
    "\n",
    "        # Compute triple scores dismult\n",
    "        score = torch.sum(source_emb * relation_emb * target_emb, dim=-1)\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CompGCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CompGCNConv\n",
    "\n",
    "The implementation of CompGCNConv is in the file `nbfnet/compgcn/compgcn_conv.py`. However, to make the code more readable, we copied the implementation of CompGCNConv to this notebook in the following code cell. This code cell is not runnable, but it is here to show our implementation of CompGCNConv. Notice that we extend the original CompGCNConv implementation to incorporate edge features.\n",
    "\n",
    "#### Incorporating Edge Features in CompGCNConv\n",
    "\n",
    "In the original CompGCNConv implementation, edge features were not explicitly considered. To enrich the representation power of the model, we extended CompGCNConv to handle edge embeddings.\n",
    "\n",
    "This extended implementation modifies the message method to include edge embeddings:\n",
    "1.\tTransforming Edge Embeddings: Depending on the specified edge method, edge embeddings are either directly added to the relation embeddings or transformed via a learnable weight matrix before addition.\n",
    "2.\tCombining Edge Features with Messages: The edge embeddings are integrated into the message-passing process at different stages, depending on the edge method chosen.\n",
    "\n",
    "#### Efficiency Improvements\n",
    "\n",
    "The original implementation of CompGCNConv was already highly efficient due to its reliance on scatter operations for sparse aggregation. These operations scale well to large, sparse graphs. Our modifications retain this efficiency while adding the capability to model edge features, ensuring the model remains practical for large-scale datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompGCNConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    A Compositional Graph Convolutional Network (CompGCN) layer.\n",
    "    This layer supports directed graphs with multiple relation types and can incorporate edge features.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Dimension of input node features.\n",
    "        out_channels (int): Dimension of output node features.\n",
    "        num_rels (int): Number of relation types.\n",
    "        act (Callable): Activation function to apply to the output.\n",
    "        params (Namespace, optional): Additional parameters such as dropout, bias, and edge method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, num_rels, act=lambda x: x, params=None):\n",
    "        super(self.__class__, self).__init__()\n",
    "\n",
    "        # Initialize attributes\n",
    "        self.p = params\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_rels = num_rels\n",
    "        self.act = act\n",
    "        self.device = None\n",
    "\n",
    "        # Learnable weights for transformations\n",
    "        self.e_weight = get_param((in_channels, out_channels))  # For edge transformations\n",
    "        self.w_loop = get_param((in_channels, out_channels))  # For self-loops\n",
    "        self.w_in = get_param((in_channels, out_channels))  # For incoming edges\n",
    "        self.w_out = get_param((in_channels, out_channels))  # For outgoing edges\n",
    "        self.w_pp = get_param((in_channels, out_channels))  # For pairwise edges\n",
    "        self.w_rel = get_param((in_channels, out_channels))  # For relation embeddings\n",
    "        self.loop_rel = get_param((1, in_channels))  # Embedding for self-loop relation\n",
    "\n",
    "        # Regularization components\n",
    "        self.drop = torch.nn.Dropout(self.p.dropout)  # Dropout layer\n",
    "        self.bn = torch.nn.BatchNorm1d(out_channels)  # Batch normalization\n",
    "\n",
    "        # Optional bias term\n",
    "        if self.p.bias:\n",
    "            self.register_parameter(\"bias\", Parameter(torch.zeros(out_channels)))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type, rel_embed, edge_embed):\n",
    "        \"\"\"\n",
    "        Forward pass for the CompGCN layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Node features of shape (num_nodes, in_channels).\n",
    "            edge_index (torch.Tensor): Edge indices of shape (2, num_edges).\n",
    "            edge_type (torch.Tensor): Relation types of edges (num_edges,).\n",
    "            rel_embed (torch.Tensor): Relation embeddings of shape (num_rels, in_channels).\n",
    "            edge_embed (torch.Tensor, optional): Edge features (num_edges, in_channels).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Updated node features of shape (num_nodes, out_channels).\n",
    "            torch.Tensor: Updated relation embeddings of shape (num_rels, out_channels).\n",
    "        \"\"\"\n",
    "        # Initialize device and augment relation embeddings with self-loop relation\n",
    "        if self.device is None:\n",
    "            self.device = edge_index.device\n",
    "        rel_embed = torch.cat([rel_embed, self.loop_rel], dim=0)\n",
    "\n",
    "        # Partition edges into different types\n",
    "        num_pp_edge = edge_type[edge_type == edge_type.max()].size(0)\n",
    "        num_edges = (edge_index.size(1) - num_pp_edge) // 2\n",
    "        num_ent = x.size(0)\n",
    "\n",
    "        # Separate edge indices and types for in, out, and pairwise edges\n",
    "        self.in_index, self.out_index, self.pp_index = (\n",
    "            edge_index[:, :num_edges],\n",
    "            edge_index[:, num_edges : 2 * num_edges],\n",
    "            edge_index[:, 2 * num_edges :],\n",
    "        )\n",
    "        self.in_type, self.out_type, self.pp_type = (\n",
    "            edge_type[:num_edges],\n",
    "            edge_type[num_edges : 2 * num_edges],\n",
    "            edge_type[2 * num_edges :],\n",
    "        )\n",
    "\n",
    "        # Partition edge embeddings, if provided\n",
    "        if edge_embed is not None:\n",
    "            self.in_embed, self.out_embed, self.pp_embed = (\n",
    "                edge_embed[:num_edges],\n",
    "                edge_embed[num_edges : 2 * num_edges],\n",
    "                edge_embed[2 * num_edges :],\n",
    "            )\n",
    "        else:\n",
    "            self.in_embed = self.out_embed = self.pp_embed = None\n",
    "\n",
    "        # Add self-loop edges and compute normalization factors\n",
    "        self.loop_index = torch.stack([torch.arange(num_ent), torch.arange(num_ent)]).to(self.device)\n",
    "        self.loop_type = torch.full((num_ent,), rel_embed.size(0) - 1, dtype=torch.long).to(self.device)\n",
    "\n",
    "        self.in_norm = self.compute_norm(self.in_index, num_ent)\n",
    "        self.out_norm = self.compute_norm(self.out_index, num_ent)\n",
    "        self.pp_norm = self.compute_norm(self.pp_index, num_ent)\n",
    "\n",
    "        # Perform message passing for in, out, self-loop, and pairwise edges\n",
    "        in_res = self.propagate(\n",
    "            \"add\",\n",
    "            self.in_index,\n",
    "            x=x,\n",
    "            edge_type=self.in_type,\n",
    "            rel_embed=rel_embed,\n",
    "            edge_norm=self.in_norm,\n",
    "            mode=\"in\",\n",
    "            edge_embed=self.in_embed,\n",
    "        )\n",
    "        loop_res = self.propagate(\n",
    "            \"add\",\n",
    "            self.loop_index,\n",
    "            x=x,\n",
    "            edge_type=self.loop_type,\n",
    "            rel_embed=rel_embed,\n",
    "            edge_norm=None,\n",
    "            mode=\"loop\",\n",
    "            edge_embed=None,\n",
    "        )\n",
    "        out_res = self.propagate(\n",
    "            \"add\",\n",
    "            self.out_index,\n",
    "            x=x,\n",
    "            edge_type=self.out_type,\n",
    "            rel_embed=rel_embed,\n",
    "            edge_norm=self.out_norm,\n",
    "            mode=\"out\",\n",
    "            edge_embed=self.out_embed,\n",
    "        )\n",
    "        pp_res = self.propagate(\n",
    "            \"add\",\n",
    "            self.pp_index,\n",
    "            x=x,\n",
    "            edge_type=self.pp_type,\n",
    "            rel_embed=rel_embed,\n",
    "            edge_norm=self.pp_norm,\n",
    "            mode=\"pp\",\n",
    "            edge_embed=self.pp_embed,\n",
    "        )\n",
    "\n",
    "        # Aggregate results from different edge types\n",
    "        out = (\n",
    "            self.drop(in_res) * (1 / 4)\n",
    "            + self.drop(out_res) * (1 / 4)\n",
    "            + loop_res * (1 / 4)\n",
    "            + self.drop(pp_res) * (1 / 4)\n",
    "        )\n",
    "\n",
    "        # Apply bias and batch normalization\n",
    "        if self.p.bias:\n",
    "            out = out + self.bias\n",
    "        out = self.bn(out)\n",
    "\n",
    "        # Return updated node and relation embeddings\n",
    "        return self.act(out), torch.matmul(rel_embed, self.w_rel)[:-1]\n",
    "\n",
    "    def rel_transform(self, ent_embed, rel_embed):\n",
    "        \"\"\"\n",
    "        Apply a compositional transformation between entity and relation embeddings.\n",
    "\n",
    "        Args:\n",
    "            ent_embed (torch.Tensor): Entity embeddings.\n",
    "            rel_embed (torch.Tensor): Relation embeddings.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Transformed embeddings.\n",
    "        \"\"\"\n",
    "        if self.p.opn == \"corr\":\n",
    "            trans_embed = ccorr(ent_embed, rel_embed)\n",
    "        elif self.p.opn == \"sub\":\n",
    "            trans_embed = ent_embed - rel_embed\n",
    "        elif self.p.opn == \"mult\":\n",
    "            trans_embed = ent_embed * rel_embed\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        return trans_embed\n",
    "\n",
    "    def message(self, x_j, edge_type, rel_embed, edge_norm, mode, edge_embed):\n",
    "        \"\"\"\n",
    "        Compute messages to be passed along edges.\n",
    "\n",
    "        Args:\n",
    "            x_j (torch.Tensor): Features of source nodes (num_edges, in_channels).\n",
    "            edge_type (torch.Tensor): Edge types (num_edges,).\n",
    "            rel_embed (torch.Tensor): Relation embeddings (num_rels, in_channels).\n",
    "            edge_norm (torch.Tensor, optional): Normalization factors for edges.\n",
    "            mode (str): Type of edges ('in', 'out', 'loop', 'pp').\n",
    "            edge_embed (torch.Tensor, optional): Edge features (num_edges, in_channels).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Messages (num_edges, out_channels).\n",
    "        \"\"\"\n",
    "        weight = getattr(self, f\"w_{mode}\")  # Select weight matrix for the mode\n",
    "        rel_emb = torch.index_select(rel_embed, 0, edge_type)  # Relation-specific embeddings\n",
    "\n",
    "        # Optionally incorporate edge embeddings\n",
    "        if edge_embed is not None:\n",
    "            if self.p.edge_method == \"method1\":\n",
    "                rel_emb = rel_emb + edge_embed\n",
    "            elif self.p.edge_method == \"method2\":\n",
    "                edge_embed_transformed = torch.mm(edge_embed, self.e_weight)\n",
    "                rel_emb = rel_emb + edge_embed_transformed\n",
    "\n",
    "        # Apply relational transformation and combine with weights\n",
    "        xj_rel = self.rel_transform(x_j, rel_emb)\n",
    "        out = torch.mm(xj_rel, weight)\n",
    "\n",
    "        # Additional edge embedding handling\n",
    "        if edge_embed is not None:\n",
    "            if self.p.edge_method == \"method3\":\n",
    "                out = out + edge_embed\n",
    "            elif self.p.edge_method == \"method4\":\n",
    "                edge_embed_transformed = torch.mm(edge_embed, self.e_weight)\n",
    "                out = out + edge_embed_transformed\n",
    "\n",
    "        return out if edge_norm is None else out * edge_norm.view(-1, 1)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        \"\"\"\n",
    "        Update step after aggregation.\n",
    "\n",
    "        Args:\n",
    "            aggr_out (torch.Tensor): Aggregated node features.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Updated node features.\n",
    "        \"\"\"\n",
    "        return aggr_out\n",
    "\n",
    "    def compute_norm(self, edge_index, num_ent):\n",
    "        \"\"\"\n",
    "        Compute edge normalization factors.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.Tensor): Edge indices (2, num_edges).\n",
    "            num_ent (int): Number of entities (nodes).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Edge normalization factors (num_edges,).\n",
    "        \"\"\"\n",
    "        row, col = edge_index\n",
    "        edge_weight = torch.ones_like(row).float()\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_ent)  # Degree of nodes\n",
    "        norm = edge_weight / ((deg[row].pow(0.5) + deg[col].pow(0.5)))\n",
    "        return norm\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        String representation of the layer.\n",
    "        \"\"\"\n",
    "        return \"{}({}, {}, num_rels={})\".format(\n",
    "            self.__class__.__name__, self.in_channels, self.out_channels, self.num_rels\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CompGCN Model\n",
    "The implementation of the `CompGCN` is in the file `nbfnet/compgcn/models.py`. The following code cell is a simplified version of the RGCN model for explaining purposes.\n",
    "\n",
    "The `CompGCN` class serves as the main entry point, initializing the appropriate variant of the model (`CompGCN_TransE` or `CompGCN_DistMult`) based on the chosen scoring function. These variants build upon the `CompGCNBase`, which implements the core graph convolutional layers using the `CompGCNConv` module. Each layer processes node features, relation embeddings, and optional edge embeddings, iteratively updating the node and relation representations. The forward pass uses initialized node embeddings, passes them through the layers, and computes scores for triples by extracting subject, relation, and object embeddings.\n",
    "\n",
    "The TransE variant computes scores using a distance-based metric in the embedding space, while the DistMult variant uses an element-wise multiplication of the subject, relation, and object embeddings followed by a summation. Both variants use dropout for regularization to improve generalization. The implementation also leverages bases for parameter sharing in relation-specific embeddings, making it efficient for large graphs with many relation types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CompGCNConfig:\n",
    "    \"\"\"\n",
    "    Configuration class for the CompGCN model.\n",
    "\n",
    "    Attributes:\n",
    "        input_dim (int): Dimension of input features for nodes.\n",
    "        num_layers (int): Number of layers in the CompGCN.\n",
    "        num_bases (int): Number of bases for relation-specific weight sharing.\n",
    "        use_stage (int): Whether to enable edge embedding usage (1 for yes, 0 for no).\n",
    "        score_func (str): Scoring function ('distmult' or 'transe').\n",
    "        dropout (float): Dropout rate for input embeddings.\n",
    "        hid_drop (float): Dropout rate for hidden layers.\n",
    "        gamma (float): Margin used in scoring function.\n",
    "        bias (int): Whether to include bias terms (1 for yes, 0 for no).\n",
    "        opn (str): Compositional operator to use ('corr', 'sub', 'mult').\n",
    "        edge_method (str): Method to handle edge embeddings ('method1', 'method2', 'method3').\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: Ensures valid configuration parameters during initialization.\n",
    "    \"\"\"\n",
    "\n",
    "    input_dim: int = 256\n",
    "    num_layers: int = 2\n",
    "    num_bases: int = 0\n",
    "    use_stage: int = 1\n",
    "    score_func: str = \"distmult\"\n",
    "    dropout: float = 0.1\n",
    "    hid_drop: float = 0.3\n",
    "    gamma: float = 40.0  # Margin\n",
    "    bias: int = 1\n",
    "    opn: str = \"corr\"\n",
    "    edge_method: str = \"method1\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # Validate configuration parameters\n",
    "        assert self.edge_method in [\"method1\", \"method2\", \"method3\"]\n",
    "        assert self.opn in [\"corr\", \"sub\", \"mult\"]\n",
    "        assert self.score_func in [\"transe\", \"distmult\"]\n",
    "        assert self.use_stage in [0, 1]\n",
    "\n",
    "\n",
    "class CompGCN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    CompGCN model for multi-relational graphs, supporting edge embeddings.\n",
    "\n",
    "    Args:\n",
    "        num_relation (int): Number of relation types.\n",
    "        edge_embed_dim (int or None): Dimension of edge embeddings (if applicable).\n",
    "        cfg (CompGCNConfig): Configuration object for CompGCN.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_relation, edge_embed_dim, cfg: CompGCNConfig):\n",
    "        super(CompGCN, self).__init__()\n",
    "\n",
    "        # Disable edge embeddings if not using STAGE\n",
    "        if not cfg.use_stage:\n",
    "            edge_embed_dim = None\n",
    "        self.edge_embed_dim = edge_embed_dim\n",
    "\n",
    "        # Select the model based on the scoring function\n",
    "        if cfg.score_func == \"transe\":\n",
    "            self.model = CompGCN_TransE(num_relation // 2, edge_embed_dim, cfg)\n",
    "        elif cfg.score_func == \"distmult\":\n",
    "            self.model = CompGCN_DistMult(num_relation // 2, edge_embed_dim, cfg)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, data, batch):\n",
    "        \"\"\"\n",
    "        Forward pass for CompGCN.\n",
    "\n",
    "        Args:\n",
    "            data (Data): Graph data containing edge indices, edge types, and optional edge embeddings.\n",
    "            batch (torch.Tensor): Tensor of triples (source, relation, target).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Scores for the input triples.\n",
    "        \"\"\"\n",
    "        # Set the number of nodes in the graph\n",
    "        self.num_nodes = data.num_nodes\n",
    "        self.model.num_nodes = self.num_nodes\n",
    "\n",
    "        # Extract edge data\n",
    "        edge_index = data.edge_index\n",
    "        edge_type = data.original_edge_type\n",
    "\n",
    "        # Extract edge embeddings if enabled\n",
    "        if self.edge_embed_dim is not None:\n",
    "            edge_embed = data.edge_embeddings\n",
    "        else:\n",
    "            edge_embed = None\n",
    "\n",
    "        # Extract batch data (source, target, relation triples)\n",
    "        source_nodes = batch[:, :, 0]\n",
    "        target_nodes = batch[:, :, 1]\n",
    "        relations = batch[:, :, 2]\n",
    "\n",
    "        # Forward through the selected model\n",
    "        return self.model(edge_index, edge_type, source_nodes, relations, target_nodes, edge_embed)\n",
    "\n",
    "\n",
    "class BaseModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for CompGCN models, providing common utilities.\n",
    "\n",
    "    Args:\n",
    "        cfg (CompGCNConfig): Configuration object for the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg: CompGCNConfig):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.act = torch.tanh  # Activation function\n",
    "        self.bceloss = torch.nn.BCELoss()  # Binary cross-entropy loss\n",
    "\n",
    "    def loss(self, pred, true_label):\n",
    "        \"\"\"\n",
    "        Compute loss for binary classification tasks.\n",
    "\n",
    "        Args:\n",
    "            pred (torch.Tensor): Predictions.\n",
    "            true_label (torch.Tensor): Ground truth labels.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Computed loss value.\n",
    "        \"\"\"\n",
    "        return self.bceloss(pred, true_label)\n",
    "\n",
    "\n",
    "class CompGCNBase(BaseModel):\n",
    "    \"\"\"\n",
    "    Base class for CompGCN layers with forward propagation.\n",
    "\n",
    "    Args:\n",
    "        num_rel (int): Number of relations.\n",
    "        edge_embed_dim (int or None): Dimension of edge embeddings.\n",
    "        cfg (CompGCNConfig): Configuration object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_rel, edge_embed_dim, cfg: CompGCNConfig):\n",
    "        super(CompGCNBase, self).__init__(cfg)\n",
    "\n",
    "        # Initialize relation embeddings\n",
    "        if self.cfg.num_bases > 0:\n",
    "            self.init_rel = get_param((self.cfg.num_bases, self.cfg.input_dim))\n",
    "        else:\n",
    "            self.init_rel = get_param(\n",
    "                (num_rel * 2 if self.cfg.score_func != \"transe\" else num_rel, self.cfg.input_dim)\n",
    "            )\n",
    "\n",
    "        # Initialize CompGCN layers\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for _ in range(self.cfg.num_layers):\n",
    "            self.layers.append(\n",
    "                CompGCNConv(self.cfg.input_dim, self.cfg.input_dim, num_rel, act=self.act, params=self.cfg)\n",
    "            )\n",
    "\n",
    "    def forward_base(self, edge_index, edge_type, sub, rel, obj, drop, edge_embed=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the base CompGCN model.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.Tensor): Edge indices.\n",
    "            edge_type (torch.Tensor): Edge types.\n",
    "            sub (torch.Tensor): Subject node indices.\n",
    "            rel (torch.Tensor): Relation indices.\n",
    "            obj (torch.Tensor): Object node indices.\n",
    "            drop (torch.nn.Dropout): Dropout layer.\n",
    "            edge_embed (torch.Tensor, optional): Edge embeddings.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: Subject, relation, and object embeddings.\n",
    "        \"\"\"\n",
    "        # Initialize relation embeddings\n",
    "        r = self.init_rel if self.cfg.score_func != \"transe\" else torch.cat([self.init_rel, -self.init_rel], dim=0)\n",
    "\n",
    "        # Initialize node features\n",
    "        init_embed = torch.ones((self.num_nodes, self.cfg.input_dim), device=sub.device)\n",
    "        x = init_embed\n",
    "\n",
    "        # Pass through all layers\n",
    "        for layer in self.layers:\n",
    "            x, r = layer(x, edge_index, edge_type, rel_embed=r, edge_embed=edge_embed)\n",
    "            x = drop(x)\n",
    "\n",
    "        # Extract embeddings for subjects, relations, and objects\n",
    "        batch_size, num_neg_plus_1 = sub.size()\n",
    "        sub_emb = torch.index_select(x, 0, sub.view(-1)).view(batch_size, num_neg_plus_1, -1)\n",
    "        rel_emb = torch.index_select(r, 0, rel.view(-1)).view(batch_size, num_neg_plus_1, -1)\n",
    "        obj_emb = torch.index_select(x, 0, obj.view(-1)).view(batch_size, num_neg_plus_1, -1)\n",
    "\n",
    "        return sub_emb, rel_emb, obj_emb\n",
    "\n",
    "\n",
    "class CompGCN_TransE(CompGCNBase):\n",
    "    \"\"\"\n",
    "    CompGCN model with TransE scoring function.\n",
    "\n",
    "    Args:\n",
    "        num_rel (int): Number of relations.\n",
    "        edge_embed_dim (int or None): Dimension of edge embeddings.\n",
    "        cfg (CompGCNConfig): Configuration object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_rel, edge_embed_dim, cfg: CompGCNConfig):\n",
    "        super(self.__class__, self).__init__(num_rel, edge_embed_dim, cfg)\n",
    "        self.drop = torch.nn.Dropout(self.cfg.hid_drop)\n",
    "\n",
    "    def forward(self, edge_index, edge_type, sub, rel, obj, edge_embed=None):\n",
    "        # Compute embeddings for subjects, relations, and objects\n",
    "        sub_emb, rel_emb, obj_emb = self.forward_base(edge_index, edge_type, sub, rel, obj, self.drop, edge_embed)\n",
    "\n",
    "        # TransE scoring function: score based on distance in embedding space\n",
    "        pred_emb = sub_emb + rel_emb\n",
    "        x = self.cfg.gamma - torch.norm(pred_emb.unsqueeze(1) - obj_emb, p=1, dim=2)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CompGCN_DistMult(CompGCNBase):\n",
    "    \"\"\"\n",
    "    CompGCN model with DistMult scoring function.\n",
    "\n",
    "    Args:\n",
    "        num_rel (int): Number of relations.\n",
    "        edge_embed_dim (int or None): Dimension of edge embeddings.\n",
    "        cfg (CompGCNConfig): Configuration object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_rel, edge_embed_dim, cfg: CompGCNConfig):\n",
    "        super(self.__class__, self).__init__(num_rel, edge_embed_dim, cfg)\n",
    "        self.drop = torch.nn.Dropout(self.cfg.hid_drop)\n",
    "\n",
    "    def forward(self, edge_index, edge_type, sub, rel, obj, edge_embed=None):\n",
    "        # Compute embeddings for subjects, relations, and objects\n",
    "        sub_emb, rel_emb, obj_emb = self.forward_base(edge_index, edge_type, sub, rel, obj, self.drop, edge_embed)\n",
    "\n",
    "        # DistMult scoring function: element-wise multiplication followed by summation\n",
    "        x = sub_emb * rel_emb * obj_emb\n",
    "        x = torch.sum(x, dim=2)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBFNet\n",
    "The STAGE framework has already implemented the NBFNet model, providing all the necessary components and functionality. As a result, we did not make any modifications or additional implementations for NBFNet. Instead, we utilized the existing implementation directly, allowing us to focus on integrating it into our overall workflow and evaluating its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGE + Friends\n",
    "The `EdgeGraphsModel` model combines STAGE embeddings with a final graph model (NBFNet, RGCN, or CompGCN) to perform relational learning tasks. The model is configured through the `EdgeGraphsModelConfig`, which allows customization of edge embedding dimensions, the number of layers in the edge embedding module, the type of edge model (GINEConv or GCNConv), and the final model to use.\n",
    "\n",
    "The model first generates edge embeddings using an `MPNN` (Message Passing Neural Network) module. The `MPNN` processes edge graphs through message passing and supports either `GINEConv` or `GCNConv` for convolution operations. Edge graph embeddings are pooled using a global pooling operation (`global_add_pool`) to generate a compact representation for each edge graph. Additionally, uniform embeddings are generated for user-product edges, ensuring consistent representation for edges without associated graph embeddings. These embeddings are then concatenated to create a unified edge embedding matrix.\n",
    "\n",
    "The processed edge embeddings are added to the graph data object and passed to the selected final model, which could be NBFNet, RGCN, or CompGCN, as specified in the configuration. Each of these models operates on the relational graph data to perform link prediction tasks.\n",
    "\n",
    "This implementation is efficient and scalable, utilizing sparse operations and pooling for edge graph embeddings and supporting multi-relational graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GINEConv, GCNConv\n",
    "from torch_geometric.nn.pool import global_add_pool\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from .nbfmodel import NBFNet, NBFNetConfig\n",
    "from .rgcn import RGCN, RGCNConfig\n",
    "from .compgcn.models import CompGCN, CompGCNConfig\n",
    "\n",
    "\n",
    "class MPNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Message Passing Neural Network (MPNN) for edge embedding generation.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Input feature dimension for nodes.\n",
    "        hidden_dim (int): Hidden layer dimension.\n",
    "        num_layers (int): Number of MPNN layers.\n",
    "        edge_model (str): Type of edge model ('GINEConv' or 'GCNConv').\n",
    "        edge_dim (int): Dimension of edge attributes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, edge_model, edge_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()  # Convolution layers\n",
    "        self.bns = torch.nn.ModuleList()  # Batch normalization layers\n",
    "\n",
    "        # Initialize layers\n",
    "        for _ in range(num_layers):\n",
    "            if edge_model == \"GINEConv\":\n",
    "                mlp = torch.nn.Sequential(\n",
    "                    torch.nn.Linear(input_dim, hidden_dim),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                )\n",
    "                self.convs.append(GINEConv(nn=mlp, edge_dim=edge_dim))\n",
    "            elif edge_model == \"GCNConv\":\n",
    "                self.convs.append(GCNConv(input_dim, hidden_dim))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
    "            input_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        Forward pass through the MPNN.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Node features.\n",
    "            edge_index (torch.Tensor): Edge indices.\n",
    "            edge_attr (torch.Tensor): Edge attributes.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Updated node features.\n",
    "        \"\"\"\n",
    "        for conv, bn in zip(self.convs, self.bns):\n",
    "            x = conv(x, edge_index, edge_attr)  # Message passing\n",
    "            x = bn(x).relu()  # Batch normalization and ReLU activation\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EdgeGraphsNBFNetConfig:\n",
    "    \"\"\"\n",
    "    Configuration class for EdgeGraphsNBFNet.\n",
    "\n",
    "    Attributes:\n",
    "        edge_embed_dim (int): Dimension of edge embeddings.\n",
    "        edge_embed_num_layers (int): Number of layers in the edge embedding MPNN.\n",
    "        edge_model (str): Edge model type ('GINEConv' or 'GCNConv').\n",
    "        use_p_value (int): Whether to use p-values in edge attributes.\n",
    "\n",
    "        final_model (str): Final model type ('nbf', 'rgcn', or 'compgcn').\n",
    "        nbf (NBFNetConfig): Configuration for NBFNet.\n",
    "        rgcn (RGCNConfig): Configuration for RGCN.\n",
    "        compgcn (CompGCNConfig): Configuration for CompGCN.\n",
    "    \"\"\"\n",
    "\n",
    "    edge_embed_dim: int = 256\n",
    "    edge_embed_num_layers: int = 1\n",
    "    edge_model: str = \"GINEConv\"\n",
    "    use_p_value: int = 1\n",
    "\n",
    "    final_model: str = \"nbf\"\n",
    "    nbf: NBFNetConfig = field(default_factory=NBFNetConfig)\n",
    "    rgcn: RGCNConfig = field(default_factory=RGCNConfig)\n",
    "    compgcn: CompGCNConfig = field(default_factory=CompGCNConfig)\n",
    "\n",
    "\n",
    "class EdgeGraphsNBFNet(nn.Module):\n",
    "    \"\"\"\n",
    "    EdgeGraphsNBFNet combines edge graph embeddings with NBFNet, RGCN, or CompGCN.\n",
    "\n",
    "    Args:\n",
    "        num_relation (int): Number of relations in the graph.\n",
    "        cfg (EdgeGraphsNBFNetConfig): Configuration object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_relation, cfg: EdgeGraphsNBFNetConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.edge_embed_dim = cfg.edge_embed_dim\n",
    "\n",
    "        # Initialize the final model based on the configuration\n",
    "        if cfg.final_model == \"nbf\":\n",
    "            self.model = NBFNet(num_relation, cfg.edge_embed_dim, cfg.nbf)\n",
    "        elif cfg.final_model == \"rgcn\":\n",
    "            self.model = RGCN(num_relation, cfg.edge_embed_dim, cfg.rgcn)\n",
    "        elif cfg.final_model == \"compgcn\":\n",
    "            self.model = CompGCN(num_relation, cfg.edge_embed_dim, cfg.compgcn)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid final model: {cfg.final_model}\")\n",
    "\n",
    "        # Define edge embedding model\n",
    "        edge_dim = 2 if cfg.use_p_value else 1  # Include p-values in edge attributes if enabled\n",
    "        self.edgegraph_model = MPNN(\n",
    "            input_dim=1,  # Edge attributes have 1 initial feature\n",
    "            hidden_dim=cfg.edge_embed_dim,\n",
    "            num_layers=cfg.edge_embed_num_layers,\n",
    "            edge_model=cfg.edge_model,\n",
    "            edge_dim=edge_dim,\n",
    "        )\n",
    "\n",
    "        # Uniform embedding for user-product edges\n",
    "        self.up_emb = torch.nn.Embedding(1, cfg.edge_embed_dim)\n",
    "\n",
    "        self.edge_model = cfg.edge_model\n",
    "        self.use_p_value = cfg.use_p_value\n",
    "\n",
    "        # Print the number of parameters in the final model\n",
    "        num_params = sum(p.numel() for p in self.model.parameters())\n",
    "        print(f\"Number of parameters in self.model: {num_params}\")\n",
    "\n",
    "    def forward(self, data, batch):\n",
    "        \"\"\"\n",
    "        Forward pass for EdgeGraphsNBFNet.\n",
    "\n",
    "        Args:\n",
    "            data (Data): Graph data containing edge features and edge graphs.\n",
    "            batch (torch.Tensor): Batch of triples for scoring.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Scores for the input triples.\n",
    "        \"\"\"\n",
    "        # Adjust edge graph attributes for compatibility with the edge model\n",
    "        if data.edgegraph_edge_attr.dim() == 1:\n",
    "            data.edgegraph_edge_attr = data.edgegraph_edge_attr.unsqueeze(-1)\n",
    "        if self.edge_model == \"GCNConv\":\n",
    "            data.edgegraph_edge_attr = data.edgegraph_edge_attr[:, 0:1]\n",
    "\n",
    "        # Generate edge graph embeddings using MPNN\n",
    "        h = self.edgegraph_model(data.edgegraph_x, data.edgegraph_edge_index, data.edgegraph_edge_attr)\n",
    "        edgegraph_reprs = global_add_pool(h, data.edgegraph2ppedge)  # Pool embeddings for each edge graph\n",
    "\n",
    "        # Generate embeddings for user-product edges\n",
    "        num_up_edges = data.edge_index.size(-1) - edgegraph_reprs.size(0)\n",
    "        upgraph_emb = self.up_emb.weight.repeat((num_up_edges, 1))\n",
    "\n",
    "        # Combine user-product and edge graph embeddings\n",
    "        edge_embeddings = torch.vstack([upgraph_emb, edgegraph_reprs])\n",
    "\n",
    "        # Add edge embeddings to the data object\n",
    "        data.edge_embeddings = edge_embeddings\n",
    "        data.x = None  # Clear node features to avoid conflicts\n",
    "\n",
    "        # Pass the processed data to the selected final model\n",
    "        return self.model.forward(data, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation Script\n",
    "This bash script automates the process of training and evaluating three models (`CompGCN`, `RGCN`, and `NBFNet`) on a multi-dataset setup. For each target dataset (phone, refrig, shoe, bed, desktop), the script trains on the remaining four datasets and tests on the target dataset specified by the corresponding YAML configuration file (`config/${config}.yaml`). For each target dataset, it iterates over four edge embedding methods (`method1`, `method2`, `method3`, and `method4`) and trains both the `CompGCN` and `RGCN` models using the specified method. The results are saved in separate directories (`exp/final_${config}/compgcn_${method}` and `exp/final_${config}/rgcn_${method}`) and also WandB plots. Additionally, the NBFNet model is trained and tested on the target dataset without varying the edge embedding method, with results saved in `exp/final_${config}/nbf`. This setup ensures a systematic evaluation across all datasets, embedding methods, and models.\n",
    "\n",
    "All the plots and numerical results used in the post are generated using the output files from this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for config in phone refrig shoe bed\n",
    "do\n",
    "    for method in method1 method2 method3 method4\n",
    "    do\n",
    "        python script/run.py --config_path config/${config}.yaml --use_wb 1 --save_dir exp/final_${config}/compgcn_${method} --edgegraph.compgcn.edge_method $method --seed 1 --edgegraph.final_model compgcn\n",
    "        python script/run.py --config_path config/${config}.yaml --use_wb 1 --save_dir exp/final_${config}/rgcn_${method} --edgegraph.compgcn.edge_method $method --seed 1 --edgegraph.final_model rgcn\n",
    "    done\n",
    "    python script/run.py --config_path config/${config}.yaml --use_wb 1 --save_dir exp/final_${config}/nbf --edgegraph.final_model nbf --seed 1  --edgegraph.final_model nbf\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
