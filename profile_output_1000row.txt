Timer unit: 1e-09 s

Total time: 0.0122348 s
File: /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py
Function: load_max_connected at line 99

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    99                                           @line_profiler.profile
   100                                           def load_max_connected(data, user2node, product2node):
   101         2      43880.0  21940.0      0.4      assert data.edge_index is not None
   102                                           
   103                                               # Convert to scipy sparse matrix
   104         2    5797537.0    3e+06     47.4      adj = to_scipy_sparse_matrix(data.edge_index, num_nodes=data.num_nodes)
   105                                           
   106                                               # Find connected components
   107         4    1284024.0 321006.0     10.5      num_components, component_labels = sp.csgraph.connected_components(
   108         2       2410.0   1205.0      0.0          adj, connection="weak"
   109                                               )
   110                                           
   111         2       1550.0    775.0      0.0      if num_components <= 1:
   112                                                   return (
   113                                                       data,
   114                                                       user2node,
   115                                                       product2node,
   116                                                   )  # Return original mappings if only one component
   117                                           
   118                                               # Find the largest component
   119         2     353130.0 176565.0      2.9      _, counts = np.unique(component_labels, return_counts=True)
   120         2      32680.0  16340.0      0.3      largest_component_label = np.argmax(counts)
   121         2      46880.0  23440.0      0.4      subset_np = component_labels == largest_component_label
   122         2     109032.0  54516.0      0.9      subset = torch.from_numpy(subset_np).to(data.edge_index.device, dtype=torch.bool)
   123                                           
   124                                               # Create a subgraph with only the largest connected component
   125         2    2382666.0    1e+06     19.5      sub_data = data.subgraph(subset)
   126                                           
   127                                               # Update user and product node mappings
   128         4     717472.0 179368.0      5.9      node_idx_mapping = {
   129         2    1027073.0 513536.5      8.4          old_idx.item(): i for i, old_idx in enumerate(torch.where(subset)[0])
   130                                               }
   131         4     232120.0  58030.0      1.9      new_user2node = {
   132                                                   user: node_idx_mapping[node_id]
   133         2       1220.0    610.0      0.0          for user, node_id in user2node.items()
   134                                                   if node_id in node_idx_mapping
   135                                               }
   136         4     201981.0  50495.2      1.7      new_product2node = {
   137                                                   product: node_idx_mapping[node_id]
   138         2        710.0    355.0      0.0          for product, node_id in product2node.items()
   139                                                   if node_id in node_idx_mapping
   140                                               }
   141         2        450.0    225.0      0.0      return sub_data, new_user2node, new_product2node

Total time: 1.66905 s
File: /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py
Function: compute_probabilities at line 176

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   176                                           @line_profiler.profile
   177                                           def compute_probabilities(data, features_keys):
   178                                           
   179         8      24640.0   3080.0      0.0      feature_values = dict.fromkeys(
   180         4        660.0    165.0      0.0          features_keys, None
   181                                               )  # Store distinct values for each feature
   182         4       1470.0    367.5      0.0      marginal_probabilities = {}  # P(F_A = a)
   183         4       5450.0   1362.5      0.0      conditional_probabilities = {}  # P(F_{A|N} = a | F_{B|C} = b)
   184         4       3380.0    845.0      0.0      internal_conditional_probabilities = {}  # P(F_{A|C} = a | F_{B|C} = b)
   185                                           
   186        16       8890.0    555.6      0.0      for feature in features_keys:
   187        12    6522789.0 543565.8      0.4          feature_values[feature] = set(data[feature])
   188                                           
   189         4       7260.0   1815.0      0.0      total_feature_nodes = 0
   190                                           
   191                                               # Compute marginal probabilities
   192        16       6670.0    416.9      0.0      for feature in feature_values:
   193        12     441701.0  36808.4      0.0          mask = ~torch.isinf(data[feature])
   194        12     208140.0  17345.0      0.0          total_feature_nodes = torch.sum(mask).item()
   195                                           
   196        12      10420.0    868.3      0.0          marginal_probabilities[feature] = {}
   197        12      12190.0   1015.8      0.0          if (
   198        12       3570.0    297.5      0.0              feature == "price"
   199                                                   ):  # TODO: Can add a distinguisher between discrete and continous features
   200                                                       # TODO: Calculate reflect qunatile to ensure invariance,
   201                                                       # Compute cumulative probabilities for price
   202                                           
   203      2154     436761.0    202.8      0.0              for i, value in enumerate(feature_values[feature]):
   204      2150   13745966.0   6393.5      0.8                  count = (data[feature] <= value).sum().item()
   205      2150    1598775.0    743.6      0.1                  marginal_probabilities[feature][value.item()] = (
   206      2150     428921.0    199.5      0.0                      count / total_feature_nodes
   207                                                           )
   208                                                   else:
   209                                                       # Regular marginal probability calculation for non-price features
   210      4308     692191.0    160.7      0.0              for value in feature_values[feature]:
   211      4300   26825149.0   6238.4      1.6                  count = (data[feature] == value).sum().item()
   212      4300    3120727.0    725.8      0.2                  marginal_probabilities[feature][value.item()] = (
   213      4300     702050.0    163.3      0.0                      count / total_feature_nodes
   214                                                           )
   215                                           
   216      7346    1428559.0    194.5      0.1      for i in range(data.edge_index.size(-1)):
   217      7342   55262869.0   7527.0      3.3          u, v = data.edge_index[0, i], data.edge_index[1, i]
   218                                                   # TODO: Distinguish between discrete and continous features (ball method or not), currently kept simple
   219     29368    5300328.0    180.5      0.3          for feature1 in features_keys:
   220     88104   16386832.0    186.0      1.0              for feature2 in features_keys:
   221     66078  883789232.0  13374.9     53.0                  if torch.isinf(data[feature1][u]) or torch.isinf(data[feature2][v]):
   222                                                               continue
   223                                           
   224     53352   11725042.0    219.8      0.7                  key = (
   225     53352    9794057.0    183.6      0.6                      feature1,
   226     53352  155108098.0   2907.3      9.3                      data[feature1][u].item(),
   227     53352    8157230.0    152.9      0.5                      feature2,
   228     53352  128770562.0   2413.6      7.7                      data[feature2][v].item(),
   229                                                           )
   230     53352   16583747.0    310.8      1.0                  conditional_probabilities[key] = (
   231     53352   24094353.0    451.6      1.4                      conditional_probabilities.get(key, 0) + 1
   232                                                           )
   233                                           
   234      2154     496102.0    230.3      0.0      for i in range(data.num_nodes):
   235      8600    1675113.0    194.8      0.1          for feature1 in features_keys:
   236     25800    5543327.0    214.9      0.3              for feature2 in features_keys:
   237     19350  208799994.0  10790.7     12.5                  if torch.isinf(data[feature1][i]) or torch.isinf(data[feature2][i]):
   238                                                               continue
   239                                           
   240     10098    2497415.0    247.3      0.1                  key = (
   241     10098    1756882.0    174.0      0.1                      feature1,
   242     10098   26688711.0   2643.0      1.6                      data[feature1][i].item(),
   243     10098    1701076.0    168.5      0.1                      feature2,
   244     10098   22043111.0   2182.9      1.3                      data[feature2][i].item(),
   245                                                           )
   246     10098    5209218.0    515.9      0.3                  internal_conditional_probabilities[key] = (
   247     10098    4792239.0    474.6      0.3                      internal_conditional_probabilities.get(key, 0) + 1
   248                                                           )
   249                                           
   250                                               # Normalize conditional probabilities
   251      6948    1292624.0    186.0      0.1      for key in conditional_probabilities:
   252      6944   11216860.0   1615.3      0.7          conditional_probabilities[key] /= data.edge_index.size(-1)
   253                                           
   254      3412     645780.0    189.3      0.0      for key in internal_conditional_probabilities:
   255     10224    2365494.0    231.4      0.1          internal_conditional_probabilities[
   256      3408     554192.0    162.6      0.0              key
   257      3408     552273.0    162.1      0.0          ] /= total_feature_nodes  # assume all featured nodes have non-inf values in all features
   258                                           
   259         4       1380.0    345.0      0.0      return (
   260         4       2330.0    582.5      0.0          marginal_probabilities,
   261         4       9810.0   2452.5      0.0          conditional_probabilities,
   262         4       1190.0    297.5      0.0          internal_conditional_probabilities,
   263                                               )

Total time: 6.01944 s
File: /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py
Function: build_product_product_graph at line 145

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   145                                           @line_profiler.profile
   146                                           def build_product_product_graph(data, up_user2node, up_product2node):
   147                                           
   148         2     992214.0 496107.0      0.0      adj = to_torch_sparse_tensor(data.edge_index, size=(data.num_nodes, data.num_nodes))
   149         2    1203472.0 601736.0      0.0      twohopsadj = adj.T @ adj
   150                                           
   151         2        740.0    370.0      0.0      edge_index = []
   152                                           
   153       563     117110.0    208.0      0.0      for p1 in up_product2node.keys():
   154    169934   34577990.0    203.5      0.6          for p2 in up_product2node.keys():
   155                                           
   156    169373   22578436.0    133.3      0.4              if p1 == p2:
   157       561      60200.0    107.3      0.0                  continue
   158    343552  115100945.0    335.0      1.9              for r in range(
   159    168812 5837830718.0  34581.8     97.0                  twohopsadj[up_product2node[p1], up_product2node[p2]].int().item()
   160                                                       ):
   161      5928    3763022.0    634.8      0.1                  edge_index.append([up_product2node[p1], up_product2node[p2]])
   162                                           
   163         4     330212.0  82553.0      0.0      return Data(
   164         2      98860.0  49430.0      0.0          price=data.price,
   165         2      10370.0   5185.0      0.0          category_code=data.category_code,
   166         2       6370.0   3185.0      0.0          brand=data.brand,
   167         2    2693567.0    1e+06      0.0          edge_index=torch.tensor(edge_index).T,
   168         2      79220.0  39610.0      0.0          num_nodes=data.num_nodes,
   169                                               )

Total time: 11.259 s
File: /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py
Function: get_user_product_graph at line 13

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    13                                           @line_profiler.profile
    14                                           def get_user_product_graph(csv_file_path, start_row, end_row, category):
    15         2       5590.0   2795.0      0.0      if category is None:
    16                                                   category = "electronics.smartphone"
    17         4    5578246.0    1e+06      0.0      df_chunks = pd.read_csv(
    18         2       6940.0   3470.0      0.0          csv_file_path, chunksize=100000
    19                                               )  # Adjust chunksize based on your memory capacity
    20                                           
    21         2        660.0    330.0      0.0      user2node = {}  # from user id to node id
    22         2        370.0    185.0      0.0      product2node = {}  # from product id to node id
    23         2        490.0    245.0      0.0      edge_index = []
    24         2        470.0    235.0      0.0      edge_attr = []
    25         2      15510.0   7755.0      0.0      event_type_mapping = {
    26         2        400.0    200.0      0.0          "view": 0,
    27         2        330.0    165.0      0.0          "cart": 1,
    28         2        460.0    230.0      0.0          "purchase": 2,
    29         2        660.0    330.0      0.0          "remove_from_cart": 3,
    30                                               }  # Mapping event types to integers
    31                                           
    32         2        550.0    275.0      0.0      category_codes = []
    33         2        480.0    240.0      0.0      cat_map = {}
    34         2        340.0    170.0      0.0      brands = []
    35         2        410.0    205.0      0.0      brand_map = {}
    36         2        350.0    175.0      0.0      prices = []
    37                                           
    38                                               # Process each chunk
    39         2        470.0    235.0      0.0      count = 0
    40         2       1130.0    565.0      0.0      break_flag = False
    41         5  504359798.0    1e+08      4.5      for df in df_chunks:
    42         5       4820.0    964.0      0.0          if break_flag:
    43         2       2710.0   1355.0      0.0              break
    44    207636 9550741123.0  45997.5     84.8          for _, row in df.iterrows():
    45    207635 1111750484.0   5354.4      9.9              if row["category_code"] != category:
    46    204633   34182782.0    167.0      0.3                  continue
    47      3002     819214.0    272.9      0.0              count += 1
    48      3002     676190.0    225.2      0.0              if count < start_row:
    49       999     148141.0    148.3      0.0                  continue
    50      2003     426520.0    212.9      0.0              if count > end_row:
    51         2        440.0    220.0      0.0                  break_flag = True
    52         2      29110.0  14555.0      0.0                  break
    53      2001    7904102.0   3950.1      0.1              user_id = row["user_id"]
    54      2001    7420806.0   3708.5      0.1              product_id = row["product_id"]
    55      2001    6904510.0   3450.5      0.1              category_code = row["category_code"]
    56      2001    6954330.0   3475.4      0.1              brand = row["brand"]
    57                                           
    58      2001     508101.0    253.9      0.0              if category_code not in cat_map:
    59         2       1210.0    605.0      0.0                  cat_map[category_code] = len(cat_map)
    60                                           
    61      2001     618641.0    309.2      0.0              if brand not in brand_map:
    62        76      39820.0    523.9      0.0                  brand_map[brand] = len(brand_map)
    63                                           
    64      2001     657121.0    328.4      0.0              if user_id not in user2node:
    65       623     456901.0    733.4      0.0                  user2node[user_id] = len(product2node) + len(user2node)
    66                                           
    67       623     608252.0    976.3      0.0                  prices.append(float("inf"))
    68       623     265230.0    425.7      0.0                  category_codes.append(float("inf"))
    69       623     261021.0    419.0      0.0                  brands.append(float("inf"))
    70      2001     644351.0    322.0      0.0              if product_id not in product2node:
    71       743     474572.0    638.7      0.0                  product2node[product_id] = len(product2node) + len(user2node)
    72                                           
    73       743    2995249.0   4031.3      0.0                  prices.append(row["price"])
    74       743     289480.0    389.6      0.0                  category_codes.append(cat_map[category_code])
    75       743     270000.0    363.4      0.0                  brands.append(brand_map[brand])
    76                                           
    77      2001     611763.0    305.7      0.0              user_node = user2node[user_id]
    78      2001     577101.0    288.4      0.0              product_node = product2node[product_id]
    79                                           
    80                                                       # only from user to product, the reverse will be added later
    81      2001     833932.0    416.8      0.0              edge_index.append([user_node, product_node])
    82      2001    7773724.0   3884.9      0.1              edge_attr.append(event_type_mapping[row["event_type"]])
    83                                           
    84                                               # Convert to tensors
    85         2    1770995.0 885497.5      0.0      edge_index_tensor = torch.tensor(edge_index).t()
    86         2     195160.0  97580.0      0.0      edge_attr_tensor = torch.tensor(edge_attr)
    87                                           
    88         4     426142.0 106535.5      0.0      data = Data(
    89         2     413111.0 206555.5      0.0          price=torch.tensor(prices),
    90         2     186460.0  93230.0      0.0          category_code=torch.tensor(category_codes),
    91         2     145630.0  72815.0      0.0          brand=torch.tensor(brands),
    92         2        900.0    450.0      0.0          edge_index=edge_index_tensor,
    93         2        460.0    230.0      0.0          edge_attr=edge_attr_tensor,
    94         2       4400.0   2200.0      0.0          num_nodes=len(user2node) + len(product2node),
    95                                               )
    96         2       4100.0   2050.0      0.0      feature_keys = ["price", "category_code", "brand"]
    97         2       1510.0    755.0      0.0      return data, user2node, product2node, feature_keys

Total time: 934.396 s
File: /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py
Function: build_edge_graph at line 265

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   265                                           @line_profiler.profile
   266                                           def build_edge_graph(
   267                                               data, u, v, marginal_prob, conditional_prob, internal_conditional_prob
   268                                           ):
   269      5928    1616865.0    272.8      0.0      tuple2node = {}
   270      5928    1163383.0    196.3      0.0      x = []
   271      5928     784170.0    132.3      0.0      edge_index = []
   272      5928     962131.0    162.3      0.0      edge_attr = []
   273                                           
   274                                               # Add edges based on conditional probabilities
   275                                               # Only add edges if both features are present in either node u or v
   276  23023144 4856073964.0    210.9      0.5      for (
   277  23017216 2757886347.0    119.8      0.3          feature_u,
   278  23017216 2396811989.0    104.1      0.3          value_u,
   279  23017216 2462228750.0    107.0      0.3          feature_v,
   280  23017216 2668094954.0    115.9      0.3          value_v,
   281  23023144 2932994685.0    127.4      0.3      ), prob in conditional_prob.items():
   282  23017216        2e+11   7714.8     19.0          hasfeature_u = ~torch.isinf(data[feature_u])
   283  23017216        2e+11   6939.8     17.1          hasfeature_v = ~torch.isinf(data[feature_v])
   284  23017216        1e+11   4139.3     10.2          if (hasfeature_u[u] and hasfeature_v[v]) or (
   285                                                       hasfeature_v[u] and hasfeature_u[v]
   286                                                   ):
   287                                                       # Ensure both feature values match those in u or v before adding the edge
   288  23017216        2e+11   6790.9     16.7              if value_u == data[feature_u][u] and value_v == data[feature_v][v]:
   289     53352   27570537.0    516.8      0.0                  if (feature_u, value_u, u) not in tuple2node:
   290      6330    4056771.0    640.9      0.0                      tuple2node[(feature_u, value_u, u)] = len(tuple2node)
   291      6330    5033358.0    795.2      0.0                      x.append(marginal_prob[feature_u][value_u])
   292     53352   16107905.0    301.9      0.0                  if (feature_v, value_v, v) not in tuple2node:
   293     17133    8159649.0    476.3      0.0                      tuple2node[(feature_v, value_v, v)] = len(tuple2node)
   294     17133    9732902.0    568.1      0.0                      x.append(marginal_prob[feature_v][value_v])
   295                                           
   296    106704   27752085.0    260.1      0.0                  edge_index.append(
   297     53352   12826057.0    240.4      0.0                      [
   298     53352   15066692.0    282.4      0.0                          tuple2node[(feature_u, value_u, u)],
   299     53352   12470348.0    233.7      0.0                          tuple2node[(feature_v, value_v, v)],
   300                                                               ]
   301                                                           )
   302     53352   13359255.0    250.4      0.0                  edge_attr.append(prob)
   303                                           
   304  23017216        2e+11   6588.2     16.2              if value_u == data[feature_u][v] and value_v == data[feature_v][u]:
   305     53352   26944935.0    505.0      0.0                  if (feature_u, value_u, v) not in tuple2node:
   306       651     353720.0    543.3      0.0                      tuple2node[(feature_u, value_u, v)] = len(tuple2node)
   307       651     431190.0    662.4      0.0                      x.append(marginal_prob[feature_u][value_u])
   308     53352   16712863.0    313.3      0.0                  if (feature_v, value_v, u) not in tuple2node:
   309     11454    6407400.0    559.4      0.0                      tuple2node[(feature_v, value_v, u)] = len(tuple2node)
   310     11454    6818108.0    595.3      0.0                      x.append(marginal_prob[feature_v][value_v])
   311                                           
   312    106704   29804100.0    279.3      0.0                  edge_index.append(
   313     53352   12935681.0    242.5      0.0                      [
   314     53352   15277936.0    286.4      0.0                          tuple2node[(feature_u, value_u, v)],
   315     53352   13494797.0    252.9      0.0                          tuple2node[(feature_v, value_v, u)],
   316                                                               ]
   317                                                           )
   318     53352   12614676.0    236.4      0.0                  edge_attr.append(prob)
   319                                           
   320                                                           # TODO: Can add relationship type (same feature, opposite node) or
   321                                                           # (different feature, opposite node) or (different feature, same node)
   322                                           
   323   4892208 1316188797.0    269.0      0.1      for (
   324   4886280  907682262.0    185.8      0.1          feature_u,
   325   4886280  846983027.0    173.3      0.1          value_u,
   326   4886280  831106274.0    170.1      0.1          feature_v,
   327   4886280  888557560.0    181.8      0.1          value_v,
   328   4892208  938189156.0    191.8      0.1      ), prob in internal_conditional_prob.items():
   329   4886280        4e+10   7872.7      4.1          hasfeature_u = ~torch.isinf(data[feature_u])
   330   4886280        3e+10   7034.9      3.7          hasfeature_v = ~torch.isinf(data[feature_v])
   331   4886280        2e+10   4215.3      2.2          if (hasfeature_u[u] and hasfeature_v[u]) or (
   332                                                       hasfeature_u[v] and hasfeature_v[v]
   333                                                   ):
   334   4886280        4e+10   7812.3      4.1              if value_u == data[feature_u][u] and value_v == data[feature_v][u]:
   335     53352   27871222.0    522.4      0.0                  if (feature_u, value_u, u) not in tuple2node:
   336                                                               tuple2node[(feature_u, value_u, u)] = len(tuple2node)
   337                                                               x.append(marginal_prob[feature_u][value_u])
   338     53352   17760713.0    332.9      0.0                  if (feature_v, value_v, u) not in tuple2node:
   339                                                               tuple2node[(feature_v, value_v, u)] = len(tuple2node)
   340                                                               x.append(marginal_prob[feature_v][value_v])
   341                                           
   342    106704   32714780.0    306.6      0.0                  edge_index.append(
   343     53352   14952912.0    280.3      0.0                      [
   344     53352   16301835.0    305.6      0.0                          tuple2node[(feature_u, value_u, u)],
   345     53352   15396791.0    288.6      0.0                          tuple2node[(feature_v, value_v, u)],
   346                                                               ]
   347                                                           )
   348     53352   15893499.0    297.9      0.0                  edge_attr.append(prob)
   349                                           
   350   4886280        4e+10   7633.8      4.0              if value_u == data[feature_u][v] and value_v == data[feature_v][v]:
   351     53352   25308726.0    474.4      0.0                  if (feature_u, value_u, v) not in tuple2node:
   352                                                               tuple2node[(feature_u, value_u, v)] = len(tuple2node)
   353                                                               x.append(marginal_prob[feature_u][value_u])
   354     53352   17354788.0    325.3      0.0                  if (feature_v, value_v, v) not in tuple2node:
   355                                                               tuple2node[(feature_v, value_v, v)] = len(tuple2node)
   356                                                               x.append(marginal_prob[feature_v][value_v])
   357                                           
   358    106704   34065295.0    319.3      0.0                  edge_index.append(
   359     53352   14789370.0    277.2      0.0                      [
   360     53352   17251329.0    323.3      0.0                          tuple2node[(feature_u, value_u, v)],
   361     53352   15576549.0    292.0      0.0                          tuple2node[(feature_v, value_v, v)],
   362                                                               ]
   363                                                           )
   364     53352   16493885.0    309.2      0.0                  edge_attr.append(prob)
   365                                           
   366     11856  337615758.0  28476.4      0.0      return Data(
   367      5928   78480276.0  13238.9      0.0          x=torch.tensor(x).view(-1, 1),
   368      5928  108970540.0  18382.3      0.0          edge_index=torch.tensor(edge_index).T,
   369      5928   35942536.0   6063.2      0.0          edge_attr=torch.tensor(edge_attr),
   370                                               )

  0.01 seconds - /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py:99 - load_max_connected
  1.67 seconds - /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py:176 - compute_probabilities
  6.02 seconds - /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py:145 - build_product_product_graph
 11.26 seconds - /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py:13 - get_user_product_graph
934.40 seconds - /lfs/ampere1/0/yangyi/feature_invariant/NBFNet-PyG/nbfnet/data_utils.py:265 - build_edge_graph
